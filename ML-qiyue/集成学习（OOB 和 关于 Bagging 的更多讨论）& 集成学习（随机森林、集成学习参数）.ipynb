{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](集成学习-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](集成学习-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**三、scikit-learn 中使用特征取样方式**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在 scikit-learn 的集成学习算法 BaggingClassifier 中封装了变量，来使用不同的取样方式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **模拟数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_moons(n_samples=500, noise=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用 oob**\n",
    "- bootstrap = True：使用 Bagging 取样方式按<font face=\"微软雅黑\" color=\"red\" size=1>样本取样</font>；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                                n_estimators=500,\n",
    "                                max_samples=100,\n",
    "                                bootstrap=True,\n",
    "                                oob_score=True\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X, y)\n",
    "bagging_clf.oob_score_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **设置并行处理：n_jobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=100, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bagging_clf2 = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=500, \n",
    "                               max_samples=100, \n",
    "                               bootstrap=True, \n",
    "                               oob_score=True,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "bagging_clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random Patches 方式：即针对样本数量，又针对特征进行取样；**\n",
    "\n",
    "- BaggingClassifier() 的参数：   \n",
    " bootstrap = True：表示采用放回的方式对样本进行取样；  \n",
    " max_samples=100：表示每次取 100 个样本；   \n",
    " bootstrap_features=True：表示采用放回取样的方式对特征进行取样；   \n",
    " max_features=1：每次给样本取 1 个特征 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_subspaces_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=500, max_samples=100, \n",
    "                               bootstrap=True, oob_score=True,\n",
    "                               n_jobs=-1, max_features=1, bootstrap_features=True)\n",
    "random_subspaces_clf.fit(X, y)\n",
    "random_subspaces_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这种使用 决策树算法集成学习得到的子模型，称为随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成学习（随机森林、集成学习参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一、基础理解**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1）定义**  \n",
    "定义：使用决策树算法进行集成学习时所得到的集成学习的模型，称为随机森林；  \n",
    "只要集成学习的底层算法是 决策树算法，最终得到的模型都可以称为随机森林；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2）scikit-learn 中：随机森林分类器及回归器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForestClassifier()：分类器\n",
    "- RandomForestRegressor()：回归器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特点：所有子模型在节点划分时，都是在<font face=\"微软雅黑\" size=1 color=\"red\">随机的特征子集</font>上寻找最优的划分特征；\n",
    "也就是在迭代寻找划分维度及其阈值时，不是对全部特征进行搜索，而是对部分特征进行搜索； \n",
    "- 优点：这种方式增加了每一个子模型的随机性及差异性； "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=True, random_state=666, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, random_state=666, oob_score=True, n_jobs=-1)\n",
    "rf_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3）scikit-learn 中：Extra-Trees（极其随机的森林）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **特点**：决策树子模型在节点划分时，使用随机的特征和随机的阈值；\n",
    "1, 也就是说，节点划分时，选择的特征及对应的特征值不是搜索比较所得，而是随机抽取一个特征，再从该特征中随机抽取一个特征值，作为该节点划分的依据；\n",
    "\n",
    "- **理论支撑**：只要子模型的准确率大于 50%，并且集成的子模型的数量足够多，最终整个集成系统的准确率就能达到要求；\n",
    "- **优点**：提供额外的随机性，抑制过拟合；并且具有更快的训练速度；\n",
    "- **缺点**：增大了 bias（偏差）；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用格式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                     n_jobs=None, oob_score=True, random_state=666, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_clf = ExtraTreesClassifier(n_estimators=500, bootstrap=True, oob_score=True, random_state=666)\n",
    "et_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4）大多数集成学习算法都可以解决回归问题**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决分类问题的算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决回归问题的算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 两类算法的参数相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***二、随机森林中的参数***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1）属于决策树算法和集成学习算法共同的参数**  \n",
    "\n",
    "max_depth = None：决策树的最高深度；（如果不做设置，按其它参数条件结束划分）  \n",
    "max_features = 'auto'：节点划分时，进行所搜的特征的种类数；（默认搜索全部特征）  \n",
    "max_leaf_nodes = None：划分结束时，模型最多的叶子数；（如果不做设置，按其它参数条件结束划分）  \n",
    "min_impurity_decrease = 0.0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
